{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain.vectorstores.pgvector import DistanceStrategy\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import psycopg\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = \"../data/raw\"  # Caminho para o diretório com PDFs\n",
    "PG_CONNECTION_STRING = \"postgresql://langchain:langchain@localhost:5435/langchain\"\n",
    "EMBEDDING_SERVICE_URL = \"http://localhost:11434/api/embeddings\"\n",
    "COLLECTION_NAME = \"my_docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Insert- Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 Adding new documents: 47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Função para carregar documentos PDF\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "# Função para dividir documentos em chunks\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Função para obter a função de embedding\n",
    "def get_embedding_function():\n",
    "    # Verificar se o serviço de embeddings está acessível\n",
    "    # try:\n",
    "    #     response = requests.get(EMBEDDING_SERVICE_URL)\n",
    "    #     response.raise_for_status()\n",
    "    #     print(\"Conexão com a API de embeddings bem-sucedida\")\n",
    "    # except requests.exceptions.RequestException as e:\n",
    "    #     print(f\"Erro ao conectar à API de embeddings: {e}\")\n",
    "    #     raise\n",
    "    return OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    # return SpacyEmbeddings(model_name=\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Função para calcular IDs únicos para chunks\n",
    "def calculate_chunk_ids(chunks):\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Função para verificar se um ID já existe no banco de dados\n",
    "def document_id_exists(engine, collection_name, doc_id):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT 1\n",
    "            FROM langchain_pg_embedding e\n",
    "            JOIN langchain_pg_collection c ON e.collection_id = c.uuid\n",
    "            WHERE c.name = :collection_name AND e.cmetadata->>'id' = :doc_id\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {\"collection_name\": collection_name, \"doc_id\": doc_id})\n",
    "        return result.scalar() is not None\n",
    "\n",
    "# Função para adicionar documentos e embeddings ao banco de dados PostgreSQL\n",
    "def add_to_pgvector(chunks: list[Document]):\n",
    "    embeddings = get_embedding_function()\n",
    "    \n",
    "    # Conectar ao banco de dados PostgreSQL usando SQLAlchemy\n",
    "    engine = create_engine(PG_CONNECTION_STRING)\n",
    "\n",
    "    # Calcular IDs dos chunks\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Adicionar documentos ao banco de dados\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        new_chunks.append(chunk)\n",
    "        # if not document_id_exists(engine, COLLECTION_NAME, chunk.metadata[\"id\"]):\n",
    "        #     new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"👉 Adding new documents: {len(new_chunks)}\")\n",
    "        db = PGVector(\n",
    "            embeddings=embeddings,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            connection=PG_CONNECTION_STRING,\n",
    "            use_jsonb=True,\n",
    "            distance_strategy=DistanceStrategy.COSINE\n",
    "        )\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "    else:\n",
    "        print(\"✅ No new documents to add\")\n",
    "\n",
    "# Executar as funções para processar e armazenar documentos\n",
    "documents = load_documents()\n",
    "chunks = split_documents(documents)\n",
    "add_to_pgvector(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB-Inser-Llama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Sequence, Optional\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from llama_index.core import Settings, VectorStoreIndex, load_index_from_storage, StorageContext, \\\n",
    "    Document as LIDocument, get_response_synthesizer, DocumentSummaryIndex\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "from llama_index.core.base.base_query_engine import BaseQueryEngine\n",
    "from llama_index.core.indices.base import BaseIndex\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core.llms.function_calling import FunctionCallingLLM\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser, SentenceSplitter, HierarchicalNodeParser, \\\n",
    "    get_leaf_nodes\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor, SentenceTransformerRerank\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine, SubQuestionQueryEngine\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.vector_stores.postgres import PGVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summary_index(docs: list[LIDocument]) -> BaseIndex:\n",
    "    llm = load_llamaindex_model()\n",
    "\n",
    "    splitter = SentenceSplitter(chunk_size=get_child_chunk_size())\n",
    "    response_synthesizer = get_response_synthesizer(\n",
    "        response_mode=ResponseMode.TREE_SUMMARIZE, use_async=True\n",
    "    )\n",
    "    doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "        docs,\n",
    "        llm=llm,\n",
    "        transformations=[splitter],\n",
    "        response_synthesizer=response_synthesizer,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    doc_summary_index.storage_context.persist(summary_index_folder)\n",
    "    #storage_context = StorageContext.from_defaults(persist_dir=summary_index_folder)\n",
    "    #doc_summary_index = load_index_from_storage(storage_context)\n",
    "    return doc_summary_index\n",
    "  \n",
    "def build_automerging_index(\n",
    "    documents,\n",
    "    save_dir=f\"{llama_index_root_dir}/{merging_index_dir}\",\n",
    "    chunk_sizes=None\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    # merging_context = ServiceContext.from_defaults(\n",
    "    #     llm=llm,\n",
    "    #     embed_model=embed_model,\n",
    "    # )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context,\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "        )\n",
    "    return automerging_index\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    save_dir=f\"{llama_index_root_dir}/{sentence_index_dir}\"\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    text_splitter = SentenceSplitter()\n",
    "    Settings.text_splitter = text_splitter\n",
    "    if not os.path.exists(save_dir):\n",
    "\n",
    "        nodes = node_parser.get_nodes_from_documents(documents)\n",
    "        # base_nodes = text_splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "        sentence_index = VectorStoreIndex(nodes)\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "\n",
    "        # base_index = VectorStoreIndex(base_nodes)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "def create_chunks(documents: Sequence[Document], method: str) -> VectorStoreIndex:\n",
    "    if method == 'sentence_window':\n",
    "        return build_sentence_window_index(documents)\n",
    "    elif method == 'automerging':\n",
    "        return build_automerging_index(documents)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method for chunk creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_store_embeddings(documents: Sequence[Document], index_type: str, save_dir: str):\n",
    "    index = create_chunks(documents, index_type)\n",
    "    index.storage_context.persist(persist_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_documents(documents: Sequence[LIDocument], save_dir: str) -> DocumentSummaryIndex:\n",
    "    index = build_summary_index(documents)\n",
    "    index.storage_context.persist(save_dir)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando a Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embedding_function()\n",
    "db = PGVector(\n",
    "            embeddings=embeddings,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            connection=PG_CONNECTION_STRING,\n",
    "            use_jsonb=True,\n",
    "            distance_strategy=DistanceStrategy.COSINE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Query for which we want to find semantically similar documents\"How much total money does a player start with in Monopoly? (Answer with the number only)\"\n",
    "query = \"What Biden told the American people when he resigned?\"\n",
    "\n",
    "#Fetch the k=3 most similar documents\n",
    "docs =  db.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content snippet:JOSEPH R. BIDEN, JR. \n",
      "July 21, 2024 \n",
      "My Fellow Americans, \n",
      "Over the past three and a half years, we have made great progress as a Nation. \n",
      "Today, America has the strongest economy in the world. We've made historic investments in \n",
      "rebuilding our Nation, in lowering prescription drug costs for seniors, and in expanding \n",
      "affordable health care to a record number of Americans. We've provided critically needed care \n",
      "to a n1illion veterans exposed to toxic substances. Passed the first gun safety law i\n",
      "Document title: data\\carta-desistencia-Biden-21jul2024.pdf\n"
     ]
    }
   ],
   "source": [
    "# Interact with a document returned from the similarity search on pgvector\n",
    "doc = docs[0]\n",
    "\n",
    "# Access the document's content\n",
    "doc_content = doc.page_content\n",
    "# Access the document's metadata object\n",
    "doc_metadata = doc.metadata\n",
    "\n",
    "print(\"Content snippet:\" + doc_content[:500])\n",
    "print(\"Document title: \" + doc_metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando o RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The provided context does not provide information about how to federate in Prometheus, as it only discusses the rules of Monopoly.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "response = rag_chain.invoke(\"how to federate on prometheus\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=PROMPT_TEMPLATE)\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=model, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=db.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query = \"What Biden told the American people when he resigned\"\n",
    "response = qa_stuff.invoke(query, prompt=prompt.format(context=chunks, question=query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " In the provided context, it does not appear that Joseph R. Biden Jr. mentioned anything about resigning or stepping down from his position as President of the United States. Instead, he expressed his intention to seek reelection but ultimately decided it would be in the best interest of his party and the country for him to step down and focus solely on fulfilling his duties as President for the remainder of his term."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "def get_embedding_function():\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "connection_string = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import FAISS,PGVector\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exemplo de uso da função\n",
    "examples = [\n",
    "    {\"input\": \"List all categories.\", \"query\": \"SELECT * FROM categoria;\"},\n",
    "    {\"input\": \"Find all products in the 'Café Gourmet' category.\", \"query\": \"SELECT * FROM produto WHERE categoria_id = (SELECT id FROM categoria WHERE nome = 'Café Gourmet');\"},\n",
    "    {\"input\": \"List all products with a price greater than 20.\", \"query\": \"SELECT * FROM produto WHERE preco > 20;\"},\n",
    "    {\"input\": \"Find the total quantity sold of 'Café Tradicional 500g'.\", \"query\": \"SELECT SUM(quantidade) FROM vendas WHERE produto_id = (SELECT id FROM produto WHERE nome = 'Café Tradicional 500g');\"},\n",
    "    {\"input\": \"List all sales from the last 30 days.\", \"query\": \"SELECT * FROM vendas WHERE data_venda >= NOW() - INTERVAL '30 days';\"},\n",
    "    {\"input\": \"Find the total sales value.\", \"query\": \"SELECT SUM(valor_total) FROM vendas;\"},\n",
    "    {\"input\": \"List all sales for 'Café Orgânico 500g'.\", \"query\": \"SELECT * FROM vendas WHERE produto_id = (SELECT id FROM produto WHERE nome = 'Café Orgânico 500g');\"},\n",
    "    {\"input\": \"List all categories and the number of products in each category.\", \"query\": \"SELECT c.nome AS categoria, COUNT(p.id) AS num_produtos FROM categoria c LEFT JOIN produto p ON c.id = p.categoria_id GROUP BY c.id, c.nome;\"},\n",
    "    {\"input\": \"Find the product with the highest price.\", \"query\": \"SELECT * FROM produto ORDER BY preco DESC LIMIT 1;\"},\n",
    "    {\"input\": \"List all categories and products with price less than 20.\", \"query\": \"SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20;\"},\n",
    "]\n",
    "\n",
    "\n",
    "def create_prompt_template(examples=examples, dialect='PostgreSQL', top_k=5):\n",
    "    \"\"\"\n",
    "    Cria um prompt template usando exemplos fornecidos e configurações específicas.\n",
    "\n",
    "    Args:\n",
    "    - examples (list of dict): Lista de exemplos com 'input' e 'query'.\n",
    "    - dialect (str): O dialeto SQL a ser utilizado na mensagem do sistema.\n",
    "    - top_k (int): Número máximo de resultados a serem retornados pela consulta.\n",
    "\n",
    "    Returns:\n",
    "    - full_prompt (ChatPromptTemplate): Template completo do prompt para o agente.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configura o seletor de exemplos\n",
    "    example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "        examples,\n",
    "        get_embedding_function(),\n",
    "       PGVector,\n",
    "        k=5,\n",
    "        input_keys=[\"input\"],\n",
    "        connection_string=\"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "       \n",
    "    )\n",
    "\n",
    "    # Mensagem do sistema com o dialeto SQL e limite de resultados\n",
    "    system_prefix = f\"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to the following tools: {{tool_names}}. Use these tools to interact with the database.\n",
    "Only use the information returned by the tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
    "\n",
    "Here are some examples of user inputs and their corresponding SQL queries:\"\"\"\n",
    "\n",
    "\n",
    "    # Cria o template de FewShotPrompt\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        example_selector=example_selector,\n",
    "        example_prompt=PromptTemplate.from_template(\n",
    "            \"User input: {input}\\nSQL query: {query}\"\n",
    "        ),\n",
    "        input_variables=[\"input\", \"dialect\", \"top_k\"],\n",
    "        prefix=system_prefix,\n",
    "        suffix=\"\",\n",
    "    )\n",
    "\n",
    "    # Cria o template de ChatPrompt\n",
    "    full_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate(prompt=few_shot_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Did not find connection_string, please add an environment variable `PGVECTOR_CONNECTION_STRING` which contains it, or pass `connection_string` as a named parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_prompt_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[75], line 42\u001b[0m, in \u001b[0;36mcreate_prompt_template\u001b[1;34m(examples, dialect, top_k)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    Cria um prompt template usando exemplos fornecidos e configurações específicas.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    - full_prompt (ChatPromptTemplate): Template completo do prompt para o agente.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Configura o seletor de exemplos\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     example_selector \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticSimilarityExampleSelector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m       \u001b[49m\u001b[43mPGVector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql+psycopg://langchain:langchain@localhost:6024/langchain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Mensagem do sistema com o dialeto SQL e limite de resultados\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     system_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an agent designed to interact with a SQL database.\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124mGiven an input question, create a syntactically correct \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdialect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m query to run, then look at the results of the query and return the answer.\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124mUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m results.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124mHere are some examples of user inputs and their corresponding SQL queries:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_core\\example_selectors\\semantic_similarity.py:170\u001b[0m, in \u001b[0;36mSemanticSimilarityExampleSelector.from_examples\u001b[1;34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, example_keys, vectorstore_kwargs, **vectorstore_cls_kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create k-shot example selector using example list and embeddings.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mReshuffles examples dynamically based on query similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    The ExampleSelector instantiated, backed by a vector store.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m string_examples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_example_to_text(eg, input_keys) \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m--> 170\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    174\u001b[0m     vectorstore\u001b[38;5;241m=\u001b[39mvectorstore,\n\u001b[0;32m    175\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     vectorstore_kwargs\u001b[38;5;241m=\u001b[39mvectorstore_kwargs,\n\u001b[0;32m    179\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:1017\u001b[0m, in \u001b[0;36mPGVector.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, collection_name, distance_strategy, ids, pre_delete_collection, use_jsonb, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03mReturn VectorStore initialized from texts and embeddings.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03mPostgres connection string is required\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m\"Either pass it as a parameter\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;124;03mor set the PGVECTOR_CONNECTION_STRING environment variable.\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(\u001b[38;5;28mlist\u001b[39m(texts))\n\u001b[1;32m-> 1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_delete_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_delete_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_jsonb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_jsonb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:485\u001b[0m, in \u001b[0;36mPGVector._from\u001b[1;34m(cls, texts, embeddings, embedding, metadatas, ids, collection_name, distance_strategy, connection_string, pre_delete_collection, use_jsonb, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 485\u001b[0m     connection_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    488\u001b[0m     connection_string\u001b[38;5;241m=\u001b[39mconnection_string,\n\u001b[0;32m    489\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    495\u001b[0m )\n\u001b[0;32m    497\u001b[0m store\u001b[38;5;241m.\u001b[39madd_embeddings(\n\u001b[0;32m    498\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts, embeddings\u001b[38;5;241m=\u001b[39membeddings, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:1104\u001b[0m, in \u001b[0;36mPGVector.get_connection_string\u001b[1;34m(cls, kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_connection_string\u001b[39m(\u001b[38;5;28mcls\u001b[39m, kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m-> 1104\u001b[0m     connection_string: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_dict_or_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnection_string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPGVECTOR_CONNECTION_STRING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m connection_string:\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1112\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPostgres connection string is required\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither pass it as a parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set the PGVECTOR_CONNECTION_STRING environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1115\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_core\\utils\\env.py:55\u001b[0m, in \u001b[0;36mget_from_dict_or_env\u001b[1;34m(data, key, env_key, default)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     key_for_err \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_from_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_for_err\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\costa\\OneDrive\\Área de Trabalho\\llmrag\\.venv\\Lib\\site-packages\\langchain_core\\utils\\env.py:80\u001b[0m, in \u001b[0;36mget_from_env\u001b[1;34m(key, env_key, default)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, please add an environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` which contains it, or pass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` as a named parameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Did not find connection_string, please add an environment variable `PGVECTOR_CONNECTION_STRING` which contains it, or pass `connection_string` as a named parameter."
     ]
    }
   ],
   "source": [
    "full_prompt = create_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an agent designed to interact with a SQL database.\n",
      "Given an input question, create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer.\n",
      "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\n",
      "You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
      "You have access to the following tools: . Use these tools to interact with the database.\n",
      "Only use the information returned by the tools to construct your final answer.\n",
      "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
      "\n",
      "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
      "\n",
      "If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
      "\n",
      "Here are some examples of user inputs and their corresponding SQL queries:\n",
      "\n",
      "User input: List all categories.\n",
      "SQL query: SELECT * FROM categoria;\n",
      "\n",
      "User input: List all categories and the number of products in each category.\n",
      "SQL query: SELECT c.nome AS categoria, COUNT(p.id) AS num_produtos FROM categoria c LEFT JOIN produto p ON c.id = p.categoria_id GROUP BY c.id, c.nome;\n",
      "\n",
      "User input: List all categories and products with price less than 20.\n",
      "SQL query: SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20;\n",
      "\n",
      "User input: Find all products in the 'Café Gourmet' category.\n",
      "SQL query: SELECT * FROM produto WHERE categoria_id = (SELECT id FROM categoria WHERE nome = 'Café Gourmet');\n",
      "\n",
      "User input: List all products with a price greater than 20.\n",
      "SQL query: SELECT * FROM produto WHERE preco > 20;\n",
      "Human: List all categories\n"
     ]
    }
   ],
   "source": [
    "prompt_val = full_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"List all categories\",\n",
    "        \"top_k\": 5,\n",
    "        \"dialect\": \"PostgreSQL\",\n",
    "        \"agent_scratchpad\": [],\n",
    "        \"tool_names\": '',\n",
    "    \"tools\": '',\n",
    "        \n",
    "    }\n",
    ")\n",
    "print(prompt_val.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.sql_database import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0.2, model_name=\"mixtral-8x7b-32768\", api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5433/llm-rag\"\n",
    ")\n",
    "db = SQLDatabase(engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tool_names = [tool.name for tool in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names'], input_types={'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=FewShotPromptTemplate(input_variables=['tool_names'], example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000233FF732C10>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None), example_prompt=PromptTemplate(input_variables=['input', 'query'], template='User input: {input}\\nSQL query: {query}'), suffix='', prefix='You are an agent designed to interact with a SQL database.\\nGiven an input question, create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer.\\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\\nYou can order the results by a relevant column to return the most interesting examples in the database.\\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\\nYou have access to the following tools: {tool_names}. Use these tools to interact with the database.\\nOnly use the information returned by the tools to construct your final answer.\\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\nIf the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n\\nHere are some examples of user inputs and their corresponding SQL queries:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_sql_agent(\n",
    "llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    prompt=full_prompt,\n",
    "    verbose=True,\n",
    "    agent_type=\"openai-tools\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[('Café Tradicional', 'Café Tradicional 500g', Decimal('10.50')), ('Café Gourmet', 'Café Gourmet 250g', Decimal('15.75')), ('Café Tradicional', 'Café Tradicional 1kg', Decimal('18.00'))]\u001b[0m\u001b[32;1m\u001b[1;3mThe query \"SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20\" returned the following results:\n",
      "- Café Tradicional, Café Tradicional 500g, 10.50\n",
      "- Café Gourmet, Café Gourmet 250g, 15.75\n",
      "- Café Tradicional, Café Tradicional 1kg, 18.00\n",
      "These are the categories and products with a price less than 20.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"input\": \"List all categories and products with price less than 20\",\n",
    "    \"tool_names\": tool_names,\n",
    "    \"tools\": tools,\n",
    "    # \"intermediate_steps\": []  # Se precisar incluir o estado intermediário\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20;'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[('Café Tradicional', 'Café Tradicional 500g', Decimal('10.50')), ('Café Gourmet', 'Café Gourmet 250g', Decimal('15.75')), ('Café Tradicional', 'Café Tradicional 1kg', Decimal('18.00'))]\u001b[0m\u001b[32;1m\u001b[1;3mThe query \"SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20\" returned the following results:\n",
      "\n",
      "- Café Tradicional with a price of 10.50\n",
      "- Café Gourmet with a price of 15.75\n",
      "- Café Tradicional with a price of 18.00\n",
      "\n",
      "These are the categories and products with a price less than 20.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"input\": \"List all categories and products with price less than 20\",\n",
    "    \"tool_names\": \"\",\n",
    "    \"tools\": \"\",\n",
    "    # \"intermediate_steps\": []  # Se precisar incluir o estado intermediário\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mcategoria, produto, vendas\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'categoria, produto, vendas'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE categoria (\n",
      "\tid BIGINT GENERATED ALWAYS AS IDENTITY (INCREMENT BY 1 START WITH 1 MINVALUE 1 MAXVALUE 9223372036854775807 CACHE 1 NO CYCLE), \n",
      "\tnome TEXT NOT NULL, \n",
      "\tCONSTRAINT categoria_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from categoria table:\n",
      "id\tnome\n",
      "1\tCafé Tradicional\n",
      "2\tCafé Gourmet\n",
      "3\tCafé Orgânico\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE produto (\n",
      "\tid BIGINT GENERATED ALWAYS AS IDENTITY (INCREMENT BY 1 START WITH 1 MINVALUE 1 MAXVALUE 9223372036854775807 CACHE 1 NO CYCLE), \n",
      "\tnome TEXT NOT NULL, \n",
      "\tpreco NUMERIC(10, 2) NOT NULL, \n",
      "\tcategoria_id BIGINT, \n",
      "\tCONSTRAINT produto_pkey PRIMARY KEY (id), \n",
      "\tCONSTRAINT produto_categoria_id_fkey FOREIGN KEY(categoria_id) REFERENCES categoria (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from produto table:\n",
      "id\tnome\tpreco\tcategoria_id\n",
      "1\tCafé Tradicional 500g\t10.50\t1\n",
      "2\tCafé Gourmet 250g\t15.75\t2\n",
      "3\tCafé Orgânico 500g\t20.00\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE vendas (\n",
      "\tid BIGINT GENERATED ALWAYS AS IDENTITY (INCREMENT BY 1 START WITH 1 MINVALUE 1 MAXVALUE 9223372036854775807 CACHE 1 NO CYCLE), \n",
      "\tdata_venda TIMESTAMP WITH TIME ZONE DEFAULT now(), \n",
      "\tproduto_id BIGINT, \n",
      "\tquantidade INTEGER NOT NULL, \n",
      "\tvalor_total NUMERIC(10, 2) NOT NULL, \n",
      "\tCONSTRAINT vendas_pkey PRIMARY KEY (id), \n",
      "\tCONSTRAINT vendas_produto_id_fkey FOREIGN KEY(produto_id) REFERENCES produto (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from vendas table:\n",
      "id\tdata_venda\tproduto_id\tquantidade\tvalor_total\n",
      "1\t2024-08-14 14:27:16.505708+00:00\t1\t2\t21.00\n",
      "2\t2024-08-14 14:27:16.505708+00:00\t2\t1\t15.75\n",
      "3\t2024-08-14 14:27:16.505708+00:00\t3\t3\t60.00\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mBased on the schema provided, here are some possible queries for the given examples:\n",
      "\n",
      "User input: List all categories.\n",
      "SQL query: SELECT * FROM categoria;\n",
      "\n",
      "User input: List all categories and the number of products in each category.\n",
      "SQL query: SELECT c.nome AS categoria, COUNT(p.id) AS num_produtos FROM categoria c LEFT JOIN produto p ON c.id = p.categoria_id GROUP BY c.id, c.nome;\n",
      "\n",
      "User input: Find all products in the 'Café Gourmet' category.\n",
      "SQL query: SELECT * FROM produto WHERE categoria_id = (SELECT id FROM categoria WHERE nome = 'Café Gourmet');\n",
      "\n",
      "User input: List all categories and products with price less than 20.\n",
      "SQL query: SELECT c.nome AS categoria, p.nome AS produto, p.preco FROM categoria c JOIN produto p ON c.id = p.categoria_id WHERE p.preco < 20;\n",
      "\n",
      "User input: List all sales for 'Café Orgânico 500g'.\n",
      "SQL query: SELECT * FROM vendas WHERE produto_id = (SELECT id FROM produto WHERE nome = 'Café Orgânico 500g');\n",
      "\n",
      "Note that the queries are syntactically correct PostgreSQL queries based on the provided schema.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = agent.invoke({\n",
    "    \"input\": \"Describe all tables\",\n",
    "    \"tool_names\": \"\",\n",
    "    \"tools\": \"\",\n",
    "    # \"intermediate_steps\": []  # Se precisar incluir o estado intermediário\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT SUM(valor_total) FROM vendas WHERE EXTRACT(YEAR FROM data_venda) = 2024'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(Decimal('171.75'),)]\u001b[0m\u001b[32;1m\u001b[1;3mThe total sales value in the year 2024 was 171.75.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': ' What was the total sales value in the year 2024',\n",
       " 'output': 'The total sales value in the year 2024 was 171.75.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\": \" What was the total sales value in the year 2024\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT SUM(quantidade) FROM vendas WHERE produto_id = (SELECT id FROM produto WHERE nome = 'Café Gourmet 250g')\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(1,)]\u001b[0m\u001b[32;1m\u001b[1;3mA total of 1 unit of 'Café Gourmet 250g' was sold.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \" how many units of 'Café Gourmet 250g' were sold\",\n",
       " 'output': \"A total of 1 unit of 'Café Gourmet 250g' was sold.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\": \" how many units of 'Café Gourmet 250g' were sold\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
